# Default configuration for training a Fractal-Mamba model

# Model configuration
name: fractal_mamba
hidden_size: 768
intermediate_size: 1536
num_hidden_layers: 8
state_size: 16
time_step_rank: 4
conv_kernel: 4
expand_factor: 2

# Fractal configuration
fractal_count: 3
fractal_depth_range: [2, 5]
fractal_dim_range: [1.2, 2.4]
dropout_prob: 0.1

# Training configuration
max_length: 2048
batch_size: 16
epochs: 10
learning_rate: 1e-4
min_learning_rate: 1e-6
weight_decay: 0.01
optimizer: adamw
scheduler: cosine
clip_grad_norm: 1.0
checkpoint_freq: 1

# Data configuration
data_dir: data
chunk_size: 4096
chunk_overlap: 128
val_split: 0.1
num_workers: 4
seed: 42

# Directories
checkpoint_dir: checkpoints
log_dir: logs

# Device configuration
# Use 'auto', 'cuda', 'cuda:0', 'cuda:1', etc., or 'cpu'
device: auto